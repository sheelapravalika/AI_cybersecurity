# -*- coding: utf-8 -*-
"""SLM.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/10z1zoPR4bAVwyjqeZETX8mJnimoRhHfe
"""

# ✅ STEP 1: Install required packages
!pip install -q datasets sentence-transformers scikit-learn imbalanced-learn matplotlib seaborn

# ✅ STEP 2: Import libraries
import pandas as pd
import numpy as np
from datasets import load_dataset
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, accuracy_score, confusion_matrix
from imblearn.over_sampling import SMOTE
from sentence_transformers import SentenceTransformer
import seaborn as sns
import matplotlib.pyplot as plt

# ✅ STEP 3: Load dataset from HuggingFace
dataset = load_dataset("sonnh-tech1/cic-ids-2017", "binary")
df = dataset["train"].to_pandas()

# ✅ STEP 4: Convert Label to string (prevent dtype issues)
if df["Label"].dtype != "object":
    df["Label"] = df["Label"].astype(str)

# ✅ STEP 5: Keep numeric + label columns
df = df.select_dtypes(include=[np.number]).copy()
df["Label"] = dataset["train"]["Label"]  # Ensure label is present

# ✅ STEP 6: Sample 40k records to fit Colab CPU
df = df.sample(n=40000, random_state=42).reset_index(drop=True)

# ✅ STEP 7: Drop NA
df.dropna(inplace=True)

# ✅ STEP 8: Split features and labels
X = df.drop(columns=["Label"], errors='ignore')
y = LabelEncoder().fit_transform(df["Label"])

# ✅ STEP 9: Normalize features
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# ✅ STEP 10: Convert scaled numeric rows into text for MiniLM
text_data = pd.DataFrame(X_scaled).astype(str).agg(' '.join, axis=1).tolist()

# ✅ STEP 11: Generate sentence embeddings
model = SentenceTransformer('paraphrase-MiniLM-L6-v2')  # Better than L3-v2
X_embed = model.encode(text_data, batch_size=16, show_progress_bar=True)

# ✅ STEP 12: SMOTE to balance class distribution
X_bal, y_bal = SMOTE(random_state=42).fit_resample(X_embed, y)

# ✅ STEP 13: Train/test split
X_train, X_test, y_train, y_test = train_test_split(
    X_bal, y_bal, test_size=0.2, stratify=y_bal, random_state=42
)

# ✅ STEP 14: Train Logistic Regression on sentence embeddings
clf = LogisticRegression(max_iter=100, C=1.0, class_weight='balanced', solver='lbfgs')
clf.fit(X_train, y_train)

# ✅ STEP 15: Evaluation
y_pred = clf.predict(X_test)
acc = accuracy_score(y_test, y_pred)
print(f"\n✅ Accuracy: {acc*100:.2f}%")
print("✅ Classification Report:\n", classification_report(y_test, y_pred))

# ✅ STEP 16: Confusion Matrix
cm = confusion_matrix(y_test, y_pred)
labels = ["Benign", "Attack"]

plt.figure(figsize=(6, 5))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", xticklabels=labels, yticklabels=labels)
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.title("Confusion Matrix")
plt.show()