# -*- coding: utf-8 -*-
"""RF.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1mkpYOsSQMqAbLe7s5q1qqHlkYHnybN1a
"""

!pip install -U datasets huggingface_hub fsspec pandas scikit-learn matplotlib seaborn numpy

# âœ… STEP 2: Import Libraries
from datasets import load_dataset
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
import warnings
warnings.filterwarnings('ignore')

# âœ… STEP 3: Load CIC-IDS2017 (Binary) Dataset
from datasets import load_dataset
dataset = load_dataset("sonnh-tech1/cic-ids-2017", "binary")
df = dataset["train"].to_pandas()
print(df)

# âœ… STEP 4: Preprocess Data
#df.dropna(inplace=True)  # Drop missing rows
le = LabelEncoder()
df['Label'] = le.fit_transform(df['Label'])  # Benign=0, Threat=1
X = df.drop('Label', axis=1)
y = df['Label']
print(X,y)
X_numeric = X.select_dtypes(include=['int64', 'float64'])
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X_numeric)
print(X_scaled)
print(y)

from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, f1_score

# âœ… 1. Stratified Train/Test Split (80/20)
X_train, X_test, y_train, y_test = train_test_split(
    X_scaled, y, test_size=0.2, stratify=y, random_state=42
)

# âœ… 2. Simpler Model to avoid 99% accuracy
model = RandomForestClassifier(
    n_estimators=80,          # Fewer trees â†’ less overfitting
    max_depth=10,             # Restrict tree depth
    min_samples_split=4,      # Avoid tiny splits
    min_samples_leaf=5,       # Larger leaves = less memorization
    max_features='sqrt',
    class_weight='balanced',
    random_state=42,
    n_jobs=-1
)

#âœ… 3. Train the model
model.fit(X_train, y_train)

# âœ… 4. Predict and evaluate
y_pred = model.predict(X_test)
# âœ… 5. Accuracy and Overfitting Check
train_acc = model.score(X_train, y_train)
test_acc = model.score(X_test, y_test)

print(f"âœ… Train Accuracy: {train_acc:.4f}")
print(f"âœ… Test Accuracy:  {test_acc:.4f}")
print(f"âœ… Weighted F1 Score: {f1_score(y_test, y_pred, average='weighted'):.4f}")

# âœ… 6. Detailed Evaluation
print("\nðŸ“„ Classification Report:\n")
print(classification_report(y_test, y_pred, digits=4))

print("\nðŸ“Š Confusion Matrix:\n")
print(confusion_matrix(y_test, y_pred))

# âœ… STEP 8: Plot Confusion Matrix
conf_mat = confusion_matrix(y_test, y_pred)
sns.heatmap(conf_mat, annot=True, fmt='d', cmap='Blues', xticklabels=le.classes_, yticklabels=le.classes_)
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix')
plt.show()

# âœ… STEP 9: Feature Importancess
import numpy as np
importances = model.feature_importances_
indices = np.argsort(importances)[-10:]  # Top 10
features = X.columns if isinstance(X, pd.DataFrame) else range(len(indices))

plt.figure(figsize=(10,6))
plt.title("Top 10 Feature Importances")
plt.barh(range(len(indices)), importances[indices], align='center')
plt.yticks(range(len(indices)), [features[i] for i in indices])
plt.xlabel('Relative Importance')
plt.show()