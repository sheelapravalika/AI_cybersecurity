# -*- coding: utf-8 -*-
"""DF_O/P-RF,GB,ANN,SLM.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/123vFO1wd8DQyyr1jCKxd_BqHoVoyZa6F
"""

!pip install -U datasets huggingface_hub fsspec pandas scikit-learn matplotlib seaborn numpy sentence-transformers

from datasets import load_dataset
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.neural_network import MLPClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, f1_score
import matplotlib.pyplot as plt
import seaborn as sns
from sentence_transformers import SentenceTransformer
import warnings
warnings.filterwarnings('ignore')

# Load dataset
dataset = load_dataset("sonnh-tech1/cic-ids-2017", "binary")
df = dataset["train"].to_pandas()
print(df)

# Encode label
le = LabelEncoder()
df['Label'] = le.fit_transform(df['Label'])  # BENIGN=0, ATTACK=1

# Keep only numeric features
X = df.select_dtypes(include=['int64', 'float64']).drop(columns=['Label'])
y = df['Label']

# Normalize
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Train/test split
X_train, X_test, y_train, y_test = train_test_split(
    X_scaled, y, test_size=0.2, stratify=y, random_state=42
)

# 1Ô∏è‚É£ Random Forest
rf = RandomForestClassifier(
    n_estimators=40,         # Fewer trees
    max_depth=6,             # Shallower trees
    min_samples_leaf=10,     # Fewer splits
    class_weight='balanced',
    random_state=42,
    n_jobs=-1
)

# 2Ô∏è‚É£ ANN (MLP)
ann = MLPClassifier(
    hidden_layer_sizes=(32, 16),  # Smaller network
    activation='relu',
    max_iter=30,
    solver='adam',
    random_state=42
)

!pip install xgboost
from xgboost import XGBClassifier

gb = XGBClassifier(
    n_estimators=5,       # Fewer boosting rounds
    max_depth=2,          # Simpler trees
    learning_rate=0.03,   # Smaller updates
    tree_method='gpu_hist',
    use_label_encoder=False,
    eval_metric='logloss',
    random_state=42
)

# Convert X_scaled into sentence-style text
text_data = pd.DataFrame(X_scaled).astype(str).agg(' '.join, axis=1)

# Sentence Embedding
model_slm = SentenceTransformer('paraphrase-MiniLM-L3-v2')
X_embed = model_slm.encode(text_data.tolist(), show_progress_bar=True)

# SLM split
X_train_s, X_test_s, y_train_s, y_test_s = train_test_split(
    X_embed, y, test_size=0.2, stratify=y, random_state=42
)

# Lightweight classifier
slm_model = LogisticRegression(max_iter=1000, class_weight='balanced')
slm_model.fit(X_train_s, y_train_s)

slm_model = LogisticRegression(
    max_iter=100,
    class_weight='balanced',
    C=0.3               # Add regularization (smaller C = stronger penalty)
)

#‚úÖ STEP 5: Predict and Perform Decision Fusion

# Fit the models
rf.fit(X_train, y_train)
ann.fit(X_train, y_train)
gb.fit(X_train, y_train),
slm_model.fit(X_train_s, y_train_s) # Fit the SLM model

# Predict from all 4 models
rf_pred = rf.predict(X_test)
ann_pred = ann.predict(X_test)
gb_pred = gb.predict(X_test)
slm_pred = slm_model.predict(X_test_s)

# Stack predictions
all_preds = np.vstack([rf_pred, ann_pred, gb_pred, slm_pred])

# Majority voting
from scipy.stats import mode
fusion_pred, _ = mode(all_preds, axis=0)
fusion_pred = fusion_pred.flatten()

#‚úÖ STEP 6: Evaluate the Fused Model and Plot Confusion Matrix

acc = accuracy_score(y_test, fusion_pred)
f1 = f1_score(y_test, fusion_pred, average='weighted')

print(f"‚úÖ Fusion Accuracy: {acc:.4f}")
print(f"‚úÖ Weighted F1 Score: {f1:.4f}\n")

print("üìÑ Classification Report:\n", classification_report(y_test, fusion_pred))
print("üìä Confusion Matrix:\n", confusion_matrix(y_test, fusion_pred))

# Plot confusion matrix
conf_mat = confusion_matrix(y_test, fusion_pred)
sns.heatmap(conf_mat, annot=True, fmt='d', cmap='Blues')
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.title("Fusion Model Confusion Matrix")
plt.show()